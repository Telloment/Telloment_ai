{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2961,"status":"ok","timestamp":1715244486786,"user":{"displayName":"박진영","userId":"14131487960861266334"},"user_tz":-540},"id":"s7XTy6sTOPjj","outputId":"42c66f16-10d4-4652-e024-d7a752eac4fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","python3.9 is already the newest version (3.9.19-1+jammy1).\n","0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"]}],"source":["!apt-get install python3.9\n","\n","!sudo rm /usr/local/bin/python\n","!sudo ln -s /usr/bin/python3.9 /usr/local/bin/python\n","\n","!sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.9 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32530,"status":"ok","timestamp":1715244519314,"user":{"displayName":"박진영","userId":"14131487960861266334"},"user_tz":-540},"id":"SlctTGN92XdJ","outputId":"07b9853d-1e8b-49ba-af4f-4bdd8822621b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: gluonnlp in /usr/local/lib/python3.10/dist-packages (0.10.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from gluonnlp) (1.23.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from gluonnlp) (3.0.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gluonnlp) (24.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: mxnet-mkl==1.6.0 in /usr/local/lib/python3.10/dist-packages (1.6.0)\n","Requirement already satisfied: numpy==1.23.1 in /usr/local/lib/python3.10/dist-packages (1.23.1)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet-mkl==1.6.0) (2.31.0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from mxnet-mkl==1.6.0) (0.8.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-mkl==1.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-mkl==1.6.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-mkl==1.6.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-mkl==1.6.0) (2024.2.2)\n","Requirement already satisfied: mxnet in /usr/local/lib/python3.10/dist-packages (1.9.1)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.23.1)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.31.0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from mxnet) (0.8.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2024.2.2)\n"]}],"source":["!pip install transformers\n","!pip install sentencepiece\n","!pip install torch\n","!pip install gluonnlp pandas tqdm\n","!pip3 install mxnet-mkl==1.6.0 numpy==1.23.1\n","!pip install mxnet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8910,"status":"ok","timestamp":1715244528221,"user":{"displayName":"박진영","userId":"14131487960861266334"},"user_tz":-540},"id":"VB8khT6oHewa","outputId":"06623363-4720-42d3-96fd-0a6003e93d8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-37qjb2yj/kobert-tokenizer_67acf885f80848da8f4c5e72f7849003\n","  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-37qjb2yj/kobert-tokenizer_67acf885f80848da8f4c5e72f7849003\n","  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xW4DyXo722Tz"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModel, pipeline\n","\n","BASEMODEL_NAME = \"skt/kobert-base-v1\"\n","tokenizer = AutoTokenizer.from_pretrained(BASEMODEL_NAME)\n","model = AutoModel.from_pretrained(BASEMODEL_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q5rejoKz3KWR"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm as tqdm_auto\n","from tqdm import tqdm\n","import os\n","import gluonnlp as nlp\n","\n","#transformers\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","from transformers import BertModel\n","\n","#GPU 사용 시\n","device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2422,"status":"ok","timestamp":1715244532022,"user":{"displayName":"박진영","userId":"14131487960861266334"},"user_tz":-540},"id":"Ap9V6PPe7gXO","outputId":"6a9055d4-1b79-462a-e403-3cde564f7cec"},"outputs":[{"name":"stdout","output_type":"stream","text":["column: Index(['Sentence', 'Emotion', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', '공포',\n","       5468],\n","      dtype='object')\n"]}],"source":["df = pd.read_excel(\"/content/drive/MyDrive/dev/Telloment/sentiment-classification/한국어_단발성_대화_데이터셋.xlsx\")\n","print(f'column: {df.columns}')\n","df = df.drop(df.columns[2:], axis=1)\n","tt = 'text'\n","lb = 'labels'\n","df.rename(columns = {'Sentence' : tt}, inplace = True)\n","df.rename(columns = {'Emotion' : lb}, inplace = True)\n","label = df[lb].unique()\n","df.loc[(df['labels'] == \"공포\"), 'labels'] = 0\n","df.loc[(df['labels'] == \"분노\"), 'labels'] = 0\n","df.loc[(df['labels'] == \"혐오\"), 'labels'] = 0\n","df.loc[(df['labels'] == \"슬픔\"), 'labels'] = 1\n","df.loc[(df['labels'] == \"놀람\"), 'labels'] = 3\n","df.loc[(df['labels'] == \"중립\"), 'labels'] = 3\n","df.loc[(df['labels'] == \"행복\"), 'labels'] = 2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5BRUwXIaiOI"},"outputs":[],"source":["df2_train = pd.read_excel(\"/content/drive/MyDrive/dev/Telloment/sentiment-classification/감성대화말뭉치(최종데이터)_Training.xlsx\")\n","df2_test = pd.read_excel(\"/content/drive/MyDrive/dev/Telloment/sentiment-classification/감성대화말뭉치(최종데이터)_Validation.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1715244557920,"user":{"displayName":"박진영","userId":"14131487960861266334"},"user_tz":-540},"id":"5Q5Zmv8bcJRh","outputId":"f59d706d-1b13-4b26-ea1a-d8f2bcd84877"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['Unnamed: 0', '연령', '성별', '상황키워드', '신체질환', '감정_대분류', '감정_소분류', '사람문장1',\n","       '시스템문장1', '사람문장2', '시스템문장2', '사람문장3', '시스템문장3'],\n","      dtype='object')\n","['불안' '슬픔' '당황' '기쁨' '분노' '상처']\n","['분노' '기쁨' '불안' '당황' '슬픔' '상처']\n"]}],"source":["print(df2_train.columns)\n","print(df2_test['감정_대분류'].unique())\n","print(df2_train['감정_대분류'].unique())\n","df2_train.loc[(df2_train['감정_대분류'] == \"불안\"), '감정_대분류'] = 0\n","df2_train.loc[(df2_train['감정_대분류'] == \"슬픔\"), '감정_대분류'] = 1\n","df2_train.loc[(df2_train['감정_대분류'] == \"당황\"), '감정_대분류'] = 1\n","df2_train.loc[(df2_train['감정_대분류'] == \"기쁨\"), '감정_대분류'] = 2\n","df2_train.loc[(df2_train['감정_대분류'] == \"분노\"), '감정_대분류'] = 0\n","df2_train.loc[(df2_train['감정_대분류'] == \"상처\"), '감정_대분류'] = 1\n","# df2_train to number\n","df2_test.loc[(df2_test['감정_대분류'] == \"불안\"), '감정_대분류'] = 0\n","df2_test.loc[(df2_test['감정_대분류'] == \"슬픔\"), '감정_대분류'] = 1\n","df2_test.loc[(df2_test['감정_대분류'] == \"당황\"), '감정_대분류'] = 1\n","df2_test.loc[(df2_test['감정_대분류'] == \"기쁨\"), '감정_대분류'] = 2\n","df2_test.loc[(df2_test['감정_대분류'] == \"분노\"), '감정_대분류'] = 0\n","df2_test.loc[(df2_test['감정_대분류'] == \"상처\"), '감정_대분류'] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cS2Ml8UccNIH"},"outputs":[],"source":["data_list2_train = []\n","for q, label in zip(df2_train['사람문장1'], df2_train['감정_대분류']):\n","    data = []\n","    data.append(q)\n","    data.append(label)\n","    data_list2_train.append(data)\n","\n","data_list2_valid = []\n","for q, label in zip(df2_test['사람문장1'], df2_test['감정_대분류']):\n","    data = []\n","    data.append(q)\n","    data.append(label)\n","    data_list2_valid.append(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZSE7IUfLiK6D"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iMDN_YsgxLAk"},"outputs":[],"source":["data_list = []\n","for q, label in zip(df[tt], df[lb]):\n","    data = []\n","    data.append(q)\n","    data.append(label)\n","    data_list.append(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715244559078,"user":{"displayName":"박진영","userId":"14131487960861266334"},"user_tz":-540},"id":"dKW0nLf5fwgv","outputId":"ee1f02cd-cc62-4d80-8e1c-aa373e290c9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["96865\n"]}],"source":["data_list.extend(data_list2_train)\n","data_list.extend(data_list2_valid)\n","print(len(data_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9wvYpg_3Qx5"},"outputs":[],"source":["class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer,vocab, max_len,\n","                 pad, pair):\n","\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","\n","    def __len__(self):\n","        return (len(self.labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gkWckEuB9o2W"},"outputs":[],"source":["max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 10\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5\n","output_dir = '/content/drive/MyDrive/dev/Telloment/sentiment-classification/result_dual_dataset/'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":472,"status":"ok","timestamp":1715244560000,"user":{"displayName":"박진영","userId":"14131487960861266334"},"user_tz":-540},"id":"xqYE2hUzygNO","outputId":"a6013e0a-69c3-4f78-c46b-b593481c2e8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["['▁', '너는', '▁', '내년', '▁', '대선', '▁', '때', '▁', '투표', 'ᄒ', 'ᅡᆯ', '▁', '수', '▁', 'ᄋ', 'ᅵ', 'ᆻ', 'ᄋ', 'ᅥ', '?']\n","1654\n","[[517, 0, 0], [517, 0, 0, 0], [517, 0, 0], [517, 0, 0, 0], [517, 0, 0], [517, 0, 0, 0], [517, 0, 0], [517, 0, 0, 0], [517, 0, 0], [517, 0, 0, 0], [517, 493, 0, 0], [517, 0, 0, 0], [517, 0, 0], [517, 0, 0, 0], [517, 0, 0], [517, 491, 0, 0], [517, 494, 0, 0], [517, 0, 0, 0], [517, 491, 0, 0], [517, 0, 0, 0], [633, 0, 0]]\n"]}],"source":["from transformers import AutoModel, AutoTokenizer\n","\n","kobert = AutoModel.from_pretrained(\"skt/kobert-base-v1\")\n","\n","result = tokenizer.tokenize(\"너는 내년 대선 때 투표할 수 있어?\")\n","print(result)\n","kobert_vocab = tokenizer.get_vocab()\n","print(kobert_vocab.get('▁대선'))\n","print([tokenizer.encode(token) for token in result])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10310,"status":"ok","timestamp":1715244570309,"user":{"displayName":"박진영","userId":"14131487960861266334"},"user_tz":-540},"id":"65cn6fww-QBp","outputId":"e084d8de-5edc-428a-ce27-25230839a483"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from kobert_tokenizer import KoBERTTokenizer\n","from transformers import BertModel\n","\n","tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n","model = BertModel.from_pretrained('skt/kobert-base-v1')\n","vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')\n","\n","dataset_train, dataset_test = train_test_split(data_list, test_size=0.2, shuffle=True, random_state=34)\n","tok=tokenizer.tokenize\n","data_train = BERTDataset(dataset_train, 0, 1, tok, vocab, max_len, True, False)\n","data_test = BERTDataset(dataset_test,0, 1, tok, vocab,  max_len, True, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1715244570309,"user":{"displayName":"박진영","userId":"14131487960861266334"},"user_tz":-540},"id":"I-cQIjw3-lyE","outputId":"12e1a0ad-a112-4e66-b51a-a32d97c8b734"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E5mtzbbV-sNy"},"outputs":[],"source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes = 4,   ##클래스 수 조정##\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","\n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","\n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","\n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device),return_dict=False)\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1172,"status":"ok","timestamp":1715244571468,"user":{"displayName":"박진영","userId":"14131487960861266334"},"user_tz":-540},"id":"HFMDRarT-1xZ","outputId":"cc22113b-3b9d-42a5-90d5-0dd313d38b28"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["model = BERTClassifier(model,  dr_rate=0.5).to(device)\n","\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss() # 다중분류를 위한 대표적인 loss func\n","\n","t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)\n","\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n","\n","#정확도 측정을 위한 함수 정의\n","def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc\n","\n","train_dataloader\n","\n","#pytorch model 저장을 위한 함수\n","def save_model(model, optimizer, epoch):\n","    torch.save({\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'epoch': epoch,\n","    }, output_dir+f'telloment_senti_{epoch}.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":158,"referenced_widgets":["3b81d705f32741f09bfe278941c1593d","b6f8e245b4c44fb992d90f6a1c688d13","5fa3621c4e224253a2b5db0f317527be","eee9230de10d4675984e2cfe6e915772","89d66ef41dac48408fe9fc5d47cb3328","67a92371d49448c5afa1e0b819a6ee6e","fb9d545992fe4f7e882bcb7705c8e899","631b0d5601dd40d28424cac4604ae731","2ff006cd965c4fe58322ec104d620ae6","d13f41ea2ea84ee99bc3027625164236","36415dc3024649868c25b01783d36bbd"]},"id":"S1yeyT7D_PBU","outputId":"f1f4bb5d-eddd-489d-9dc3-1ad003a4a78d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b81d705f32741f09bfe278941c1593d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1211 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch 1 batch id 1 loss 1.4203333854675293 train acc 0.328125\n"]}],"source":["train_history=[]\n","test_history=[]\n","loss_history=[]\n","model_dir = '/content/drive/MyDrive/dev/Telloment/sentiment-classification/result_dual_dataset/model/'\n","for e in range(num_epochs):\n","    train_acc = 0.0\n","    test_acc = 0.0\n","    model.train()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_auto(train_dataloader)):\n","        optimizer.zero_grad()\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","        #print(label.shape,out.shape)\n","        loss = loss_fn(out, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()  # Update learning rate schedule\n","        train_acc += calc_accuracy(out, label)\n","        if batch_id % log_interval == 0:\n","            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n","            train_history.append(train_acc / (batch_id+1))\n","            loss_history.append(loss.data.cpu().numpy())\n","    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n","    #train_history.append(train_acc / (batch_id+1))\n","\n","    model.eval()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_auto(test_dataloader)):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        test_acc += calc_accuracy(out, label)\n","    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n","    save_model(model, optimizer, e+1)\n","    torch.save(model, model_dir+f'telloment_senti_{epoch}.pth')\n","    test_history.append(test_acc / (batch_id+1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XY3kpUiAn03"},"outputs":[],"source":["def predict(predict_sentence):\n","\n","    data = [predict_sentence, '0']\n","    dataset_another = [data]\n","\n","    another_test = BERTDataset(dataset_another, 0, 1, tok, vocab, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n","\n","    model.eval()\n","\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","\n","        test_eval=[]\n","        for i in out:\n","            logits=i\n","            logits = logits.detach().cpu().numpy()\n","\n","            if np.argmax(logits) == 0: #분\n","                test_eval.append(\"공포가\")\n","            elif np.argmax(logits) == 1:\n","                test_eval.append(\"놀람이\") #슬\n","            elif np.argmax(logits) == 2:\n","                test_eval.append(\"분노가\") #행\n","            elif np.argmax(logits) == 3:\n","                test_eval.append(\"슬픔이\") #중립이\n","\n","        print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZ4ADRYPCgpJ"},"outputs":[],"source":["sentence = '집에 가고싶다'\n","predict(sentence)\n","sentence = '엘리베이터에 갇혔었어'\n","predict(sentence)\n","sentence = '완전 럭키야!'\n","predict(sentence)\n","sentence = '모기는 왤케 많은거야'\n","predict(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4gA41XGD2WYY"},"outputs":[],"source":["#pytorch model load을 위한 함수\n","def load_model(epoch:int):\n","  torch.load(output_dir+f'telloment_senti_{epoch}.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67xbxSWai3bx"},"outputs":[],"source":["from google.colab import runtime\n","t"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"mount_file_id":"1h3iSypq3gd8WIRl7Q6XeIpGmh7L7pzKM","authorship_tag":"ABX9TyOjKCBlmHwNz5aa8g59nj0T"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2ff006cd965c4fe58322ec104d620ae6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36415dc3024649868c25b01783d36bbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b81d705f32741f09bfe278941c1593d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b6f8e245b4c44fb992d90f6a1c688d13","IPY_MODEL_5fa3621c4e224253a2b5db0f317527be","IPY_MODEL_eee9230de10d4675984e2cfe6e915772"],"layout":"IPY_MODEL_89d66ef41dac48408fe9fc5d47cb3328"}},"5fa3621c4e224253a2b5db0f317527be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_631b0d5601dd40d28424cac4604ae731","max":1211,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ff006cd965c4fe58322ec104d620ae6","value":1}},"631b0d5601dd40d28424cac4604ae731":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67a92371d49448c5afa1e0b819a6ee6e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89d66ef41dac48408fe9fc5d47cb3328":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6f8e245b4c44fb992d90f6a1c688d13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67a92371d49448c5afa1e0b819a6ee6e","placeholder":"​","style":"IPY_MODEL_fb9d545992fe4f7e882bcb7705c8e899","value":"  0%"}},"d13f41ea2ea84ee99bc3027625164236":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eee9230de10d4675984e2cfe6e915772":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d13f41ea2ea84ee99bc3027625164236","placeholder":"​","style":"IPY_MODEL_36415dc3024649868c25b01783d36bbd","value":" 1/1211 [00:47&lt;15:54:34, 47.33s/it]"}},"fb9d545992fe4f7e882bcb7705c8e899":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}